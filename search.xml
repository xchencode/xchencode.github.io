<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器阅读理解数据集]]></title>
    <url>%2F2019%2F04%2F09%2Fmrc_data%2F</url>
    <content type="text"><![CDATA[用神经网络解决阅读理解问题是当下的NLP任务的重点之一。本文对机器阅读理解任务中的数据集进行了概括介绍。 机器阅读理解中的数据集 机器阅读理解的一般任务定义是，给机器一篇或多篇文章（Passage，P），机器需要对若干问题（Question，Q）进行回答（Answer，A）。用一个式子总结就是： f(P,Q)=Af(P,Q)=A f(P,Q)=A 这里的 f 就是阅读理解的模型。模型的发展离不开数据集，数据集的不断进步直接地推动了该领域的研究进展。根据问题（Q）和回答（A）的形式，机器阅读理解中的数据集可以分为最早的完型填空形式（cloze-style）、多项选择（multi-choice）、区域预测（span-prediction）和自由形式（open-form）。经历过英语高考的各位对此都不陌生，下面对这四种形式分别介绍，并给出每种形式的代表数据集。 1、完型填空形式 完型填空类型的阅读理解问题就是在原文中挖出一个空来，由机器根据对文章上下文的理解去补全。这类比较著名的数据集有CNN/Daily Mail、Children’s Book Test(CBT)等，下文介绍了CNN/Daily Mail. CNN/Daily Mail : CNN/Daily Mail s数据集由大名鼎鼎的机器阅读理解文章《Teaching Machines to Read and Comprehend》给出。值得一提的是，该篇文章还提出了两个经典的神经机器阅读理解模型，以后再做介绍。数据集从CNN和Daily Mail的新闻中提取文章，并抽取新闻报道中重点句子的entity，将其替换为空格。为了去除额外信息，如世界知识的影响，文章中的实体被匿名的ID所代替，并打乱序号顺序，这使得模型必须依赖文本来回答问题。下图是论文给出的一个示例。 CNN/Daily Mail数据集下载：https://cs.nyu.edu/~kcho/DMQA/ 论文地址：Teaching Machines to Read and Comprehend 2、 多项选择形式 此类形式和初高中时英语阅读理解题的类型相似，甚至有数据集以中国中学生英语考试的数据为基础构建数据集（RACE）。每篇文章对应多个问题，每个问题有多个候选答案，机器需要在这些候选答案中找到最合适的那个。通常这些候选答案与原文中的句子并不相同，即使相同也可能和问题毫不相关，所以仅靠判断相似性无法取得较好的效果。此类数据集中比较著名的有MCTest、RACE等，下面介绍RACE数据集。 RACE：2017年提出，从中国初中生和高中生的英语考试中搜集了2万多篇文章和10万个问题，覆盖领域广泛，这些问题由专家或老师提出，原本是考察人类的阅读理解水平，所以回答问题需要机器有一定的推理能力。 RACE数据集下载：http://www.cs.cmu.edu/~glai1/data/race/ 论文地址：RACE: Large-scale ReAding Comprehension Dataset From Examinations 3、 区域预测形式 区域预测形式阅读理解问题也称为抽取式问答（Extractive QA），即给定文章和问题，机器需要在文章中找到答案对应的区域（span），给出开始位置和结束位置，区域的长度通常不会限制。这类数据集中最常用的是斯坦福大学的SQuAD数据集。 SQuAD:2016年，斯坦福大学提出了阅读理解数据集SQuAD，包含了在536篇维基百科手工（crowdworkers）找出的10万多个问题。每个问题对应一篇文章，问题的答案是对应文章中的一部分。 SQuAD数据集下载：https://rajpurkar.github.io/SQuAD-explorer/ 论文地址：SQuAD: 100,000+ Questions for Machine Comprehension of Text SQuAD2.0：SQuAD2.0是SQuAD1.0版本的扩展版，同样是由斯坦福大学发布。与前一个版本不同的是，在之前同样的文章中增加了5万多个新的，无法回答的问题。这些问题在相应文章中有似是而非（plausible）的答案，即和提的问题是同种类型的，但并不正确。模型需要识别这些问题从而避免回答。 SQuAD2.0 数据集地址：https://rajpurkar.github.io/SQuAD-explorer/ 论文地址：Know What You Don’t Know: Unanswerable Questions for SQuAD 4、 自由形式 自由形式的问答是所有问答形式中最难的一个，它不限定问题所处的段落，即一个问题可能是需要理解多个段落甚至多篇文章，问题的答案是人为创造的，也就是既不会给定候选答案，也不是只需要提取文章中的片段。这对机器的阅读理解能力有更高的要求。此类型的数据集比较有名的是百度的DuReader和微软的MS MARCO，两者分别从百度搜索和必应搜索中收集数据。在直觉上看，在搜索引擎中获取数据集是个很巧妙的方法，这省掉了很多人为标注的时间。下面来看DuReader。 DuReader：2017年百度发布了开领域的中文阅读理解数据集DuReader，在百度知道和百度搜索中收集了一百多万个文档和二十多万个不同类型的问题，包括YesNo问题，描述性问题等，并且手工制造答案。 DuReader数据集下载：https://ai.baidu.com//broad/subordinate?dataset=dureader 论文下载:DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications 总结 上述是对当下机器阅读理解数据集的简述，至于每个数据集中各模型的排名情况，可以移步paperwithcode查看。根据任务定义的不同，各数据集的评价指标也不尽相同。完形填空和多项选择可以直接用准确率衡量，区域预测形式可以用F1衡量。自由形式的阅读理解评价指标有多种，用到BLEU和ROUGE-L的多一些。本文提到的数据集如下： 数据集名称 数据来源 类型 文档数目 问题数目 评价指标 CNN/Daily Mail CNN,Daily Mail 完型填空 300k 1.4M 准确率 Children’s Book Test Children’s Book 完型填空 108 688k 准确率 MCTest Fictional Stories 多项选择 500 2k 准确率 RACE English Exams 多项选择 28k 97k 准确率 SQuAD Wikipedia 区域预测 536 100k F1 SQuAD2.0 Wikipedia 区域预测 505 150k F1 DuReader user logs(Baidu) 自由形式 1M 200k BLEU,ROUGE-L SQuAD user logs(Bing) 自由形式 3.2M 1M 准确率，BLEU,ROUGE-L 以上是对机器阅读理解数据集的介绍，等有时间再把相关模型写一下。 END.]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F05%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new "My New Post" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
